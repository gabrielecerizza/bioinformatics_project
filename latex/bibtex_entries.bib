@article{kelley18,
author = {Kelley, David and Reshef, Yakir and Bileschi, Maxwell and Belanger, David and McLean, Cory and Snoek, Jasper},
year = {2018},
month = {03},
pages = {739--750},
title = {Sequential regulatory activity prediction across chromosomes with convolutional neural networks},
volume = {28},
journal = {Genome Research},
doi = {10.1101/gr.227819.117}
}

@inproceedings{cappelletti20,
title = "Bayesian Optimization Improves Tissue-Specific Prediction of Active Regulatory Regions with Deep Neural Networks",
abstract = "The annotation and characterization of tissue-specific cis-regulatory elements (CREs) in non-coding DNA represents an open challenge in computational genomics. Several prior works show that machine learning methods, using epigenetic or spectral features directly extracted from DNA sequences, can predict active promoters and enhancers in specific tissues or cell lines. In particular, very recently deep-learning techniques obtained state-of-the-art results in this challenging computational task. In this study, we provide additional evidence that Feed Forward Neural Networks (FFNN) trained on epigenetic data and one-dimensional convolutional neural networks (CNN) trained on DNA sequence data can successfully predict active regulatory regions in different cell lines. We show that model selection by means of Bayesian optimization applied to both FFNN and CNN models can significantly improve deep neural network performance, by automatically finding models that best fit the data. Further, we show that techniques applied to balance active and non-active regulatory regions in the human genome in training and test data may lead to over-optimistic or poor predictions. We recommend to use actual imbalanced data that was not used to train the models for evaluating their generalization performance.",
author = "Luca Cappelletti and Alessandro Petrini and Jessica Gliozzo and Elena Casiraghi and Max Schubach and Martin Kircher and Giorgio Valentini",
year = "2020",
month = jan,
day = "1",
doi = "10.1007/978-3-030-45385-5_54",
language = "English",
isbn = "9783030453848",
series = "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
publisher = "Springer",
pages = "600--612",
editor = "Ignacio Rojas and Olga Valenzuela and Fernando Rojas and Herrera, {Luis Javier} and Francisco Ortu{\~n}o",
booktitle = "Bioinformatics and Biomedical Engineering - 8th International Work-Conference, IWBBIO 2020, Proceedings",
note = "8th International Work-Conference on Bioinformatics and Biomedical Engineering, IWBBIO 2020 ; Conference date: 06-05-2020 Through 08-05-2020",
}

@article {li_wasserman18,
	author = {Li, Yifeng and Shi, Wenqiang and Wasserman, Wyeth W.},
	title = {Genome-Wide Prediction of cis-Regulatory Regions Using Supervised Deep Learning Methods},
	year = {2018},
	doi = {10.1186/s12859-018-2187-1},
	abstract = {Identifying active cis-regulatory regions in the human genome is critical for understanding gene regulation and assessing the impact of genetic variation on phenotype. Based on rich data resources such as the Encyclopedia of DNA Elements (ENCODE) and the Functional Annotation of the Mammalian Genome (FANTOM) projects, we introduce DECRES, the first supervised deep learning approach for the identification of enhancer and promoter regions in the human genome. Due to their ability to discover patterns in large and complex data, the introduction of deep learning methods enables a significant advance in our knowledge of the genomic locations of cis-regulatory regions. Using models for well-characterized cell lines, we identify key experimental features that contribute to the predictive performance. Applying DECRES, we delineate locations of 300,000 candidate enhancers genome wide (6.8\% of the genome, of which 40,000 are supported by bidirectional transcription data) and 26,000 candidate promoters (0.6\% of the genome).},
	journal = {BMC Bioinformatics},
	volume = {19},
	number = {202}
}

@article{choi19,
title = {EmbraceNet: A robust deep learning architecture for multimodal classification},
journal = {Information Fusion},
volume = {51},
pages = {259-270},
year = {2019},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2019.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S1566253517308242},
author = {Jun-Ho Choi and Jong-Seok Lee},
keywords = {Multimodal data fusion, deep learning, classification, data loss},
abstract = {Classification using multimodal data arises in many machine learning applications. It is crucial not only to model cross-modal relationship effectively but also to ensure robustness against loss of part of data or modalities. In this paper, we propose a novel deep learning-based multimodal fusion architecture for classification tasks, which guarantees compatibility with any kind of learning models, deals with cross-modal information carefully, and prevents performance degradation due to partial absence of data. We employ two datasets for multimodal classification tasks, build models based on our architecture and other state-of-the-art models, and analyze their performance on various situations. The results show that our architecture outperforms the other multimodal fusion architectures when some parts of data are not available.}
}

@article{li_wu16,
    author = {Li, Yifeng and Wu, Fang-Xiang and Ngom, Alioune},
    title = "{A review on machine learning principles for multi-view biological data integration}",
    journal = {Briefings in Bioinformatics},
    volume = {19},
    number = {2},
    pages = {325-340},
    year = {2016},
    month = {12},
    abstract = "{Driven by high-throughput sequencing techniques, modern genomic and clinical studies are in a strong need of integrative machine learning models for better use of vast volumes of heterogeneous information in the deep understanding of biological systems and the development of predictive models. How data from multiple sources (called multi-view data) are incorporated in a learning system is a key step for successful analysis. In this article, we provide a comprehensive review on omics and clinical data integration techniques, from a machine learning perspective, for various analyses such as prediction, clustering, dimension reduction and association. We shall show that Bayesian models are able to use prior information and model measurements with various distributions; tree-based methods can either build a tree with all features or collectively make a final decision based on trees learned from each view; kernel methods fuse the similarity matrices learned from individual views together for a final similarity matrix or learning model; network-based fusion methods are capable of inferring direct and indirect associations in a heterogeneous network; matrix factorization models have potential to learn interactions among features from different views; and a range of deep neural networks can be integrated in multi-modal learning for capturing the complex mechanism of biological systems.}",
    issn = {1477-4054},
    doi = {10.1093/bib/bbw113},
    url = {https://doi.org/10.1093/bib/bbw113},
    eprint = {https://academic.oup.com/bib/article-pdf/19/2/325/25524236/bbw113.pdf},
}

@article{onimaru20,
    doi = {10.1371/journal.pone.0235748},
    author = {Onimaru, Koh AND Nishimura, Osamu AND Kuraku, Shigehiro},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Predicting gene regulatory regions with a convolutional neural network for processing double-strand genome sequence information},
    year = {2020},
    month = {07},
    volume = {15},
    url = {https://doi.org/10.1371/journal.pone.0235748},
    pages = {1-17},
    abstract = {With advances in sequencing technology, a vast amount of genomic sequence information has become available. However, annotating biological functions particularly of non-protein-coding regions in genome sequences without experiments is still a challenging task. Recently deep learning–based methods were shown to have the ability to predict gene regulatory regions from genome sequences, promising to aid the interpretation of genomic sequence data. Here, we report an improvement of the prediction accuracy for gene regulatory regions by using the design of convolution layers that efficiently process genomic sequence information, and developed a software, DeepGMAP, to train and compare different deep learning–based models (https://github.com/koonimaru/DeepGMAP). First, we demonstrate that our convolution layers, termed forward- and reverse-sequence scan (FRSS) layers, integrate both forward and reverse strand information, and enhance the power to predict gene regulatory regions. Second, we assessed previous studies and identified problems associated with data structures that caused overfitting. Finally, we introduce visualization methods to examine what the program learned. Together, our FRSS layers improve the prediction accuracy for gene regulatory regions.},
    number = {7},

}

@article{chen21,
title = {DeepCAPE: A Deep Convolutional Neural Network for the Accurate Prediction of Enhancers},
journal = {Genomics, Proteomics \& Bioinformatics},
year = {2021},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2019.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S1672022921000127},
author = {Shengquan Chen and Mingxin Gan and Hairong Lv and Rui Jiang},
keywords = {Enhancer prediction, Chromatin accessibility, Data integration, Transcription factor binding motif, Disease-associated regulatory element},
abstract = {The establishment of a landscape of enhancers across human cells is crucial to deciphering the mechanism of gene regulation, cell differentiation, and disease development. High-throughput experimental approaches, though having successfully reported enhancers in typical cell lines, are still too costly and time consuming to perform systematic identification of enhancers specific to different cell lines. Existing computational methods, though capable of predicting regulatory elements purely relying on DNA sequences, lack the power of cell line-specific screening. Recent studies have suggested that chromatin accessibility of a DNA segment is closely related to its potential function in regulation, and thus may provide useful information in identifying regulatory elements. Motivated by the above understanding, we integrate DNA sequences and chromatin accessibility data to accurately predict enhancers in a cell line-specific manner. We proposed DeepCAPE, a deep convolutional neural network to predict enhancers via the integration of DNA sequences and DNase-seq data. Benefitting from the well-designed feature extraction mechanism and skip connection strategy, our model not only consistently outperforms existing methods in the imbalanced classification of cell line-specific enhancers against background sequences, but also has the ability to self-adapt to different sizes of datasets. Besides, with the adoption of auto-encoder, our model is capable of making cross cell-line predictions. We further visualize kernels of the first convolutional layer and show the match of identified sequence signatures and known motifs. We finally demonstrate the potential ability of our model to explain functional implications of putative disease-associated genetic variants and discriminate disease-related enhancers.}
}

@article {chen_zhang21,
	author = {Chen, Zhanlin and Zhang, Jing and Liu, Jason and Dai, Yi and Lee, Donghoon and Min, Martin Renqiang and Xu, Min and Gerstein, Mark},
	title = {DECODE: A Deep-learning Framework for Condensing Enhancers and Refining Boundaries with Large-scale Functional Assays},
	elocation-id = {2021.01.27.428477},
	year = {2021},
	doi = {10.1101/2021.01.27.428477},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Summary Mapping distal regulatory elements, such as enhancers, is the cornerstone for investigating genome evolution, understanding critical biological functions, and ultimately elucidating how genetic variations may influence diseases. Previous enhancer prediction methods have used either unsupervised approaches or supervised methods with limited training data. Moreover, past approaches have operationalized enhancer discovery as a binary classification problem without accurate enhancer boundary detection, producing low-resolution annotations with redundant regions and reducing the statistical power for downstream analyses (e.g., causal variant mapping and functional validations). Here, we addressed these challenges via a two-step model called DECODE. First, we employed direct enhancer activity readouts from novel functional characterization assays, such as STARR-seq, to train a deep neural network classifier for accurate cell-type-specific enhancer prediction. Second, to improve the annotation resolution (\~{}500 bp), we implemented a weakly-supervised object detection framework for enhancer localization with precise boundary detection (at 10 bp resolution) using gradient-weighted class activation mapping.Results Our DECODE binary classifier outperformed the state-of-the-art enhancer prediction methods by 24\% in transgenic mouse validation. Further, DECODE object detection can condense enhancer annotations to only 12.6\% of the original size, while still reporting higher conservation scores and genome-wide association study variant enrichments. Overall, DECODE improves the efficiency of regulatory element mapping with graphic processing units for deep-learning applications and is a powerful tool for enhancer prediction and boundary localization.Availability DEOCDE is available at decode.gersteinlab.orgContact pi{at}gersteinlab.orgCompeting Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2021/01/28/2021.01.27.428477.1},
	eprint = {https://www.biorxiv.org/content/early/2021/01/28/2021.01.27.428477.1.full.pdf},
	journal = {bioRxiv}
}

@article {min17,
	author = {Xu Min and Ning Chen and Ting Chen and Rui Jiang},
	title = {DeepEnhancer: Predicting enhancers by convolutional neural networks},
	year = {2017},
	doi = {10.1186/s12859-017-1878-3},
	journal = {BMC Bioinformatics},
	volume = {18},
	number = {478}
}

@book{goodfellow16,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@misc{li18hyperband,
      title={Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization}, 
      author={Lisha Li and Kevin Jamieson and Giulia DeSalvo and Afshin Rostamizadeh and Ameet Talwalkar},
      year={2018},
      eprint={1603.06560},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{levesque17,
  author={Lévesque, Julien-Charles and Durand, Audrey and Gagné, Christian and Sabourin, Robert},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Bayesian optimization for conditional hyperparameter spaces}, 
  year={2017},
  volume={},
  number={},
  pages={286-293},
  doi={10.1109/IJCNN.2017.7965867}}

@misc{kerastuner,
    author={Keras-Tuner},
    howpublished={\url{https://keras-team.github.io/keras-tuner}},
}

@misc{ucsc-genomes-downloader,
    author={ucsc\_genomes\_downloader},
    howpublished={\url{https://github.com/LucaCappelletti94/ucsc_genomes_downloader}},
}

@misc{he15resnet,
      title={Deep Residual Learning for Image Recognition}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{kingma15,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{dozat16nadam,
  title={Incorporating Nesterov Momentum into Adam},
  author={Timothy Dozat},
  year={2016},
  booktitle = {ICLR Workshop},
}

@article{encode12,
author = {Dunham, Ian and Kundaje, Anshul and Aldred, Shelley and Collins, Patrick and Davis, Carrie and Doyle, Francis and Epstein, Charles and Frietze, Seth and Harrow, Jennifer and Kaul, Rajinder and Khatun, Jainab and Lajoie, Bryan and Landt, Stephen and Lee, Bum-Kyu and Pauli Behn, Florencia and Rosenbloom, Kate and Sabo, Peter and Safi, Alexias and Sanyal, Amartya and Birney, Ewan},
year = {2012},
month = {09},
pages = {57-74},
title = {The ENCODE Project Consortium: An integrated encyclopedia of DNA elements in the human genome. 2012. Nature 489: 57–74},
volume = {489},
journal = {Nature},
doi = {10.1038/nature11247}
}

@article{encode17,
    author = {Davis, Carrie A and Hitz, Benjamin C and Sloan, Cricket A and Chan, Esther T and Davidson, Jean M and Gabdank, Idan and Hilton, Jason A and Jain, Kriti and Baymuradov, Ulugbek K and Narayanan, Aditi K and Onate, Kathrina C and Graham, Keenan and Miyasato, Stuart R and Dreszer, Timothy R and Strattan, J Seth and Jolanki, Otto and Tanaka, Forrest Y and Cherry, J Michael},
    title = "{The Encyclopedia of DNA elements (ENCODE): data portal update}",
    journal = {Nucleic Acids Research},
    volume = {46},
    number = {D1},
    pages = {D794-D801},
    year = {2017},
    month = {11},
    abstract = "{The Encyclopedia of DNA Elements (ENCODE) Data Coordinating Center has developed the ENCODE Portal database and website as the source for the data and metadata generated by the ENCODE Consortium. Two principles have motivated the design. First, experimental protocols, analytical procedures and the data themselves should be made publicly accessible through a coherent, web-based search and download interface. Second, the same interface should serve carefully curated metadata that record the provenance of the data and justify its interpretation in biological terms. Since its initial release in 2013 and in response to recommendations from consortium members and the wider community of scientists who use the Portal to access ENCODE data, the Portal has been regularly updated to better reflect these design principles. Here we report on these updates, including results from new experiments, uniformly-processed data from other projects, new visualization tools and more comprehensive metadata to describe experiments and analyses. Additionally, the Portal is now home to meta(data) from related projects including Genomics of Gene Regulation, Roadmap Epigenome Project, Model organism ENCODE (modENCODE) and modERN. The Portal now makes available over 13000 datasets and their accompanying metadata and can be accessed at: https://www.encodeproject.org/.}",
    issn = {0305-1048},
    doi = {10.1093/nar/gkx1081},
    url = {https://doi.org/10.1093/nar/gkx1081},
    eprint = {https://academic.oup.com/nar/article-pdf/46/D1/D794/23162243/gkx1081.pdf},
}

@article{ucsc20,
    author = {Navarro Gonzalez, Jairo and Zweig, Ann S and Speir, Matthew L and Schmelter, Daniel and Rosenbloom, Kate R and Raney, Brian J and Powell, Conner C and Nassar, Luis R and Maulding, Nathan D and Lee, Christopher M and Lee, Brian T and Hinrichs, Angie S and Fyfe, Alastair C and Fernandes, Jason D and Diekhans, Mark and Clawson, Hiram and Casper, Jonathan and Benet-Pagès, Anna and Barber, Galt P and Haussler, David and Kuhn, Robert M and Haeussler, Maximilian and Kent, W James},
    title = "{The UCSC Genome Browser database: 2021 update}",
    journal = {Nucleic Acids Research},
    volume = {49},
    number = {D1},
    pages = {D1046-D1057},
    year = {2020},
    month = {11},
    abstract = "{For more than two decades, the UCSC Genome Browser database (https://genome.ucsc.edu) has provided high-quality genomics data visualization and genome annotations to the research community. As the field of genomics grows and more data become available, new modes of display are required to accommodate new technologies. New features released this past year include a Hi-C heatmap display, a phased family trio display for VCF files, and various track visualization improvements. Striving to keep data up-to-date, new updates to gene annotations include GENCODE Genes, NCBI RefSeq Genes, and Ensembl Genes. New data tracks added for human and mouse genomes include the ENCODE registry of candidate cis-regulatory elements, promoters from the Eukaryotic Promoter Database, and NCBI RefSeq Select and Matched Annotation from NCBI and EMBL-EBI (MANE). Within weeks of learning about the outbreak of coronavirus, UCSC released a genome browser, with detailed annotation tracks, for the SARS-CoV-2 RNA reference assembly.}",
    issn = {0305-1048},
    doi = {10.1093/nar/gkaa1070},
    url = {https://doi.org/10.1093/nar/gkaa1070},
    eprint = {https://academic.oup.com/nar/article-pdf/49/D1/D1046/35364254/gkaa1070.pdf},
}


@article{fantom18,
    author = {Lizio, Marina and Abugessaisa, Imad and Noguchi, Shuhei and Kondo, Atsushi and Hasegawa, Akira and Hon, Chung Chau and de Hoon, Michiel and Severin, Jessica and Oki, Shinya and Hayashizaki, Yoshihide and Carninci, Piero and Kasukawa, Takeya and Kawaji, Hideya},
    title = "{Update of the FANTOM web resource: expansion to provide additional transcriptome atlases}",
    journal = {Nucleic Acids Research},
    volume = {47},
    number = {D1},
    pages = {D752-D758},
    year = {2018},
    month = {11},
    abstract = "{The FANTOM web resource (http://fantom.gsc.riken.jp/) was developed to provide easy access to the data produced by the FANTOM project. It contains the most complete and comprehensive sets of actively transcribed enhancers and promoters in the human and mouse genomes. We determined the transcription activities of these regulatory elements by CAGE (Cap Analysis of Gene Expression) for both steady and dynamic cellular states in all major and some rare cell types, consecutive stages of differentiation and responses to stimuli. We have expanded the resource by employing different assays, such as RNA-seq, short RNA-seq and a paired-end protocol for CAGE (CAGEscan), to provide new angles to study the transcriptome. That yielded additional atlases of long noncoding RNAs, miRNAs and their promoters. We have also expanded the CAGE analysis to cover rat, dog, chicken, and macaque species for a limited number of cell types. The CAGE data obtained from human and mouse were reprocessed to make them available on the latest genome assemblies. Here, we report the recent updates of both data and interfaces in the FANTOM web resource.}",
    issn = {0305-1048},
    doi = {10.1093/nar/gky1099},
    url = {https://doi.org/10.1093/nar/gky1099},
    eprint = {https://academic.oup.com/nar/article-pdf/47/D1/D752/27437410/gky1099.pdf},
}


@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}
@article{fantom15,
author = {Lizio, Marina and Harshbarger, Jayson and Shimoji, H. and Severin, J. and Kasukawa, Takeya and Sahin, Serkan and Abugessaisa, I. and Fukuda, S. and Hori, Fumi and Kato, Sachi and Mungall, C.J. and Arner, E. and Baillie, Kenneth and Bertin, Nicolas and Bono, Hidemasa and de Hoon, Michiel and Diehl, Alexander and Dimont, E. and Freeman, Tom and Kawaji, H.},
year = {2015},
month = {01},
pages = {},
title = {Gateways to the FANTOM5 promoter level mammalian expression atlas},
volume = {16},
journal = {Genome Biology}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@article{kursa10boruta,
   author = {Miron B. Kursa and Witold R. Rudnicki},
   title = {Feature Selection with the Boruta Package},
   journal = {Journal of Statistical Software, Articles},
   volume = {36},
   number = {11},
   year = {2010},
   keywords = {},
   abstract = {This article describes a R package Boruta, implementing a novel feature selection algorithm for finding emph\{all relevant variables\}.  The algorithm is designed as a wrapper around a Random Forest classification algorithm. It iteratively removes the features which are proved by a statistical test to be less relevant than random probes. The Boruta package provides a convenient interface to the algorithm. The short description of the algorithm and examples of its application are presented.},
   issn = {1548-7660},
   pages = {1--13},
   doi = {10.18637/jss.v036.i11},
   url = {https://www.jstatsoft.org/v036/i11}
}

@article{leo01rf,
author = {Breiman, Leo},
title = {Random Forests},
year = {2001},
issue_date = {October 1 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {45},
number = {1},
issn = {0885-6125},
url = {https://doi.org/10.1023/A:1010933404324},
doi = {10.1023/A:1010933404324},
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
journal = {Mach. Learn.},
month = oct,
pages = {5–32},
numpages = {28},
keywords = {ensemble, classification, regression}
}


@article{ben-hur02svc,
author = {Ben-Hur, Asa and Horn, David and Siegelmann, Hava T. and Vapnik, Vladimir},
title = {Support Vector Clustering},
year = {2002},
issue_date = {3/1/2002},
publisher = {JMLR.org},
volume = {2},
issn = {1532-4435},
abstract = {We present a novel clustering method using the approach of support vector machines. Data points are mapped by means of a Gaussian kernel to a high dimensional feature space, where we search for the minimal enclosing sphere. This sphere, when mapped back to data space, can separate into several components, each enclosing a separate cluster of points. We present a simple algorithm for identifying these clusters. The width of the Gaussian kernel controls the scale at which the data is probed while the soft margin constant helps coping with outliers and overlapping clusters. The structure of a dataset is explored by varying the two parameters, maintaining a minimal number of support vectors to assure smooth cluster boundaries. We demonstrate the performance of our algorithm on several datasets.},
journal = {J. Mach. Learn. Res.},
month = mar,
pages = {125–137},
numpages = {13}
}

@article{halkidi01,
  author          = {M. Halkidi and Y. Batistakis and M. Vazirgiannis},
  title           = {{On Clustering Validation Techniques}},
  journal         = {Journal of Intelligent Information Systems},
  volume          = {17},
  pages           = {107--145},
  year            = {2001},
  publisher       = {Springer}
}

@article{liu13,
  author          = {Y. Liu and Z. Li and H. Xiong and X. Gao and J. Wu and S. Wu},
  title           = {{Understanding and Enhancement of Internal Clustering Validation Measures}},
  journal         = {IEEE Transactions on Cybernetics},
  volume          = {43},
  number          = {3},
  year            = {2013},
  pages           = {982--994}
}

@article{chawla02smote,
author = {Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip},
title = {SMOTE: Synthetic Minority over-Sampling Technique},
year = {2002},
issue_date = {January 2002},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {16},
number = {1},
issn = {1076-9757},
abstract = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of "normal" examples with only a small percentage of "abnormal" or "interesting" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of oversampling the minority (abnormal)cla ss and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space)tha n only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space)t han varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC)and the ROC convex hull strategy.},
journal = {J. Artif. Int. Res.},
month = jun,
pages = {321–357},
numpages = {37}
}